# -*- coding: utf-8 -*-
"""GRU, GRUW,GRUWA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SBL_N_t9d3sdG76XCl3ieRIx7rSAte_a
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from scipy.stats import ttest_rel

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# ================================
# 1. Load Modified Dataset
# ================================
df = pd.read_csv("/content/drive/MyDrive/Book Chapter-Weibull/weibull_attention.csv")

# Encode risk labels
le = LabelEncoder()
df['risk_label'] = le.fit_transform(df['risk'])

X = df.drop(['risk', 'risk_label'], axis=1).values
y = df['risk_label'].values

scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape for GRU: (batch, seq_len, features)
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

# ================================
# 2. PyTorch Dataset
# ================================
class RiskDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

train_loader = DataLoader(RiskDataset(X_train, y_train), batch_size=32, shuffle=True)
test_loader = DataLoader(RiskDataset(X_test, y_test), batch_size=32, shuffle=False)

# ================================
# 3. Model Definitions
# ================================
class GRUClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super(GRUClassifier, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        _, h = self.gru(x)
        out = self.fc(h[-1])
        return out

class GRUWClassifier(GRUClassifier):
    def forward(self, x):
        # Simple Weibull scaling (demo)
        _, h = self.gru(x)
        h = h[-1] * 0.9   # mimic Weibull effect
        out = self.fc(h)
        return out

class GRUWAClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_classes):
        super(GRUWAClassifier, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)
        self.attn = nn.Linear(hidden_dim, 1)
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        h_seq, _ = self.gru(x)             # (batch, seq_len, hidden)
        attn_weights = torch.softmax(self.attn(h_seq), dim=1)  # (batch, seq_len, 1)
        context = torch.sum(attn_weights * h_seq, dim=1)       # weighted sum
        out = self.fc(context)
        return out

# ================================
# 4. Training Function
# ================================
def train_model(model, train_loader, test_loader, epochs=20):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(epochs):
        model.train()
        for Xb, yb in train_loader:
            optimizer.zero_grad()
            out = model(Xb)
            loss = criterion(out, yb)
            loss.backward()
            optimizer.step()

    # Evaluate
    model.eval()
    y_pred, y_true = [], []
    with torch.no_grad():
        for Xb, yb in test_loader:
            out = model(Xb)
            preds = torch.argmax(out, dim=1)
            y_pred.extend(preds.numpy())
            y_true.extend(yb.numpy())
    return accuracy_score(y_true, y_pred)

# ================================
# 5. Run Experiments
# ================================
input_dim = X_train.shape[2]
hidden_dim = 32
num_classes = len(np.unique(y))

models = {
    "GRU": GRUClassifier(input_dim, hidden_dim, num_classes),
    "GRUW": GRUWClassifier(input_dim, hidden_dim, num_classes),
    "GRUWA": GRUWAClassifier(input_dim, hidden_dim, num_classes)
}

results = {}
for name, model in models.items():
    acc = train_model(model, train_loader, test_loader)
    results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")

# ================================
# 6. t-test Comparisons
# ================================
gru_acc = results["GRU"]
gruwa_acc = results["GRUWA"]

# Example: Paired t-test with bootstrapped runs
acc_runs_gru, acc_runs_gruwa = [], []
for run in range(5):
    model_gru = GRUClassifier(input_dim, hidden_dim, num_classes)
    model_gruwa = GRUWAClassifier(input_dim, hidden_dim, num_classes)
    acc_runs_gru.append(train_model(model_gru, train_loader, test_loader))
    acc_runs_gruwa.append(train_model(model_gruwa, train_loader, test_loader))

t_stat, p_val = ttest_rel(acc_runs_gru, acc_runs_gruwa)

print("\nStatistical Significance Test (GRU vs GRUWA):")
print(f"T-statistic = {t_stat:.4f}, p-value = {p_val:.5f}")
if p_val < 0.01:
    print("âœ… Significant improvement with GRUWA (p < 0.01)")
if p_val < 0.005:
    print("ðŸ”¥ Even larger improvements with GRUWA (p < 0.005)")