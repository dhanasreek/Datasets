# -*- coding: utf-8 -*-
"""Zero day attack analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xO86iJPFdc-xkP950HWbY8Uuxo1edzhD
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, confusion_matrix
import time

# ==============================================
# 1. Load datasets (replace with your paths)
# ==============================================
DATASETS = {
    "DNP3": "/content/drive/MyDrive/Book Chapter-Weibull/DNP3.csv",
    "CICIDS2017": "/content/drive/MyDrive/Book Chapter-Weibull/CICIDS2017.csv",
    "X-IIoTID": "/content/drive/MyDrive/Book Chapter-Weibull/X-IIoTID.csv"
}

def load_dataset(path, label_col="label"):
    df = pd.read_csv(path)
    # Encode categorical labels
    le = LabelEncoder()
    df[label_col] = le.fit_transform(df[label_col])
    X = df.drop(columns=[label_col]).values
    y = df[label_col].values
    return X, y

# ==============================================
# 2. Metrics calculation
# ==============================================
def evaluate(y_true, y_pred, y_prob, zero_day_class=1):
    acc = accuracy_score(y_true, y_pred)
    z_recall = recall_score(y_true, y_pred, pos_label=zero_day_class)
    f1 = f1_score(y_true, y_pred, average="weighted")
    roc_auc = roc_auc_score(y_true, y_prob[:,1]) if y_prob.shape[1] > 1 else 0
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    fpr = fp / (fp + tn + 1e-6) * 100
    return acc, z_recall, f1, roc_auc, fpr

# ==============================================
# 3. Dummy Model Wrappers (replace with real ones)
# ==============================================
class WADCS:
    def fit(self, X, y): pass
    def predict(self, X): return np.random.randint(0,2,len(X))
    def predict_proba(self, X): return np.random.rand(len(X),2)

class GNN_IDS(WADCS): pass
class FL_IDS(WADCS): pass
class Lightweight_IDS(WADCS): pass
class XAI_IDS(WADCS): pass

MODELS = {
    "WADCS": WADCS(),
    "GNN-IDS": GNN_IDS(),
    "FL-IDS": FL_IDS(),
    "Lightweight-IDS": Lightweight_IDS(),
    "XAI-IDS": XAI_IDS()
}

# ==============================================
# 4. Benchmark Framework
# ==============================================
results = []

for dname, dpath in DATASETS.items():
    print(f"\n=== Dataset: {dname} ===")
    X, y = load_dataset(dpath, label_col="label")
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    for mname, model in MODELS.items():
        print(f"Training {mname}...")
        start_time = time.time()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_prob = model.predict_proba(X_test)
        latency = (time.time() - start_time) / len(X_test)  # per-sample latency
        throughput = len(X_test) / (time.time() - start_time)  # samples per second

        acc, zrec, f1, roc_auc, fpr = evaluate(y_test, y_pred, y_prob, zero_day_class=1)
        results.append([dname, mname, acc, zrec, f1, roc_auc, fpr, latency, throughput])

# ==============================================
# 5. Save Results
# ==============================================
results_df = pd.DataFrame(results, columns=[
    "Dataset", "Model", "Accuracy", "Zero-day Recall", "F1-score",
    "ROC-AUC", "FPR (%)", "Latency (s/sample)", "Throughput (samples/s)"
])
results_df.to_csv("zero_day_analysis_results.csv", index=False)
print(results_df)